<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<title>EmbedSLR â€“ Comprehensive Documentation</title>
<style>
/* â”€â”€â”€ basic styling â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
body{font-family:Arial,Helvetica,sans-serif;max-width:950px;margin:auto;padding:2.2rem;line-height:1.55}
h1,h2,h3{border-bottom:1px solid #e0e0e0;padding-bottom:.2rem;margin-top:2.2rem}
code,pre{font-family:Consolas,Monaco,monospace}
pre{background:#fafafa;border:1px solid #ddd;padding:1rem;border-radius:5px;overflow-x:auto}
kbd{background:#eee;border:1px solid #ccc;border-radius:3px;padding:2px 4px;font-size:90%}
table{border-collapse:collapse;width:100%}th,td{border:1px solid #ddd;padding:.4rem}th{background:#f5f5f5}
small.note{color:#666}
</style>
</head>
<body>

<h1>EmbedSLRÂ ğŸš€ <small>Deterministic publication screening &amp; bibliometric auditing</small></h1>

<p><strong>EmbedSLR</strong> is a compact Python framework that combines <em>embeddingâ€‘based ranking</em> with an automatic bibliometric audit to accelerate the screening phase in systematic literature reviews (SLR).</p>

<ul>
  <li>Fully <strong>deterministic</strong>Â â€“ no stochastic LLM components</li>
  <li>Five interchangeable embedding backâ€‘ends: localâ€¯SBERT, OpenAI, Cohere, Jina, Nomic</li>
  <li>Two â€œ<strong>zeroâ€‘config</strong>â€ entry points: an interactive <em>Terminalâ€¯Wizard</em> and a <em>GoogleÂ ColabÂ GUI</em></li>
  <li>Creates a shareâ€‘ready dashboard: <code>biblio_report.txt</code></li>
</ul>


<h2>1&nbsp;&nbsp;Installation</h2>

<h3>1.1Â From GitHub (development version)</h3>
<pre><code>pip install git+https://github.com/s-matysik/EmbedSLR.git</code></pre>

<p>Alternatively, clone the repository and work in editable mode:</p>
<pre><code>git clone https://github.com/s-matysik/EmbedSLR.git
cd EmbedSLR
pip install -e .       # editable install
</code></pre>

<h3>1.2Â Requirements &amp; environment</h3>
<ul>
  <li><code>Python &gt;= 3.9</code></li>
  <li>Core deps: <code>pandas</code>, <code>numpy</code>, <code>scikit-learn</code>, <code>sentence-transformers</code>, <code>openai</code>, <code>cohere</code>, <code>requests</code>, <code>tqdm</code>, <code>ipywidgets</code></li>
  <li>Optional (Colab): <code>google-colab</code></li>
  <li>Cloud providers (optional): set API keys via env vars:
    <code>OPENAI_API_KEY</code>, <code>COHERE_API_KEY</code>, <code>JINA_API_KEY</code>, <code>NOMIC_API_KEY</code></li>
</ul>


<h2>2&nbsp;&nbsp;Quick start</h2>

<h3>2.1&nbsp;GoogleÂ Colab GUI&nbsp;ğŸŸ¢ (recommended for firstâ€‘time users)</h3>
<pre><code class="language-python">!pip install -q git+https://github.com/s-matysik/EmbedSLR.git
from embedslr.colab_app import run
run()   # launches an interactive widget</code></pre>

<h3>2.2&nbsp;Terminal Wizard&nbsp;âš¡ (offlineâ€‘friendly)</h3>
<ol>
  <li>Export your Scopus search results to <code>CSV</code>.</li>
  <li>Run:
  <pre><code>python -m embedslr.wizard</code></pre></li>
  <li>Provide the CSV path, research query and choose provider/model.</li>
  <li>Receive a ZIP archive (<code>ranking.csv</code>, optionalÂ <code>topN.csv</code>, <code>biblio_report.txt</code>).</li>
</ol>

<h3>2.3Â CLI (oneâ€‘shot)</h3>
<p>The commandâ€‘line interface is a single command (argparseâ€‘based):</p>
<pre><code>embedslr \
  -i scopus.csv \
  -q "How do CSR cues influence consumer behaviour?" \
  -p sbert \
  -o ranking.csv \
  -r biblio_report.txt \
  --json-embs
</code></pre>
<p class="note"><small class="note">Flags: <code>-i/--input</code>, <code>-q/--query</code>, <code>-p/--provider</code> (<code>sbert</code>|<code>openai</code>|<code>cohere</code>|<code>jina</code>|<code>nomic</code>), <code>-m/--model</code> (optional), <code>-o/--out</code>, <code>-r/--report</code>, <code>--api_key</code> (optional), <code>--json-embs</code> (save embeddings column).</small></p>

<h3>2.4Â Python API (minimal)</h3>
<pre><code class="language-python">from embedslr.io import read_csv, autodetect_columns, combine_title_abstract
from embedslr.embeddings import get_embeddings, list_models
from embedslr.similarity import rank_by_cosine
from embedslr.bibliometrics import full_report

df = read_csv("scopus.csv")
tcol, acol = autodetect_columns(df)
df["combined_text"] = combine_title_abstract(df, tcol, acol)

model = list_models()["sbert"][0]  # e.g. "sentence-transformers/all-MiniLM-L6-v2"
doc_vecs = get_embeddings(df["combined_text"].tolist(), provider="sbert", model=model)
qvec = get_embeddings(["your research question"], provider="sbert", model=model)[0]

ranked = rank_by_cosine(qvec, doc_vecs, df)
full_report(ranked, path="biblio_report.txt", top_n=30)  # if top_n omitted â†’ full dataset</code></pre>


<h2>3&nbsp;&nbsp;Local SBERT (automatic download &amp; 100â€¯% offline afterwards)</h2>

<table>
<thead><tr><th>Code fragment</th><th>Purpose</th></tr></thead>
<tbody>
<tr><td><code>_ensure_sbert_installed()</code></td><td>Checks for <code>sentenceâ€‘transformers</code>; if missing, prompts and installs it</td></tr>
<tr><td><code>_local_model_dir()</code></td><td>Resolves permanent path <code>embedslr/sbert_models/&lt;model&gt;</code></td></tr>
<tr><td><code>_get_or_download_local_sbert()</code></td><td>Downloads the model on first run, sets <code>HF_HUB_OFFLINE=1</code> for subsequent offline use</td></tr>
<tr><td><code>_select_model()</code></td><td>You enter the model only onceÂ â€“ no duplicate prompts</td></tr>
</tbody>
</table>

<p><em>Result:</em> from the second launch onward, EmbedSLR runs entirely offline even in closed networks.</p>

<h3>3.1Â Embedding providers &amp; models (builtâ€‘ins)</h3>
<pre><code class="language-text">sbert  : sentence-transformers (e.g. all-MiniLM-L6-v2)
openai : text-embedding-3-large, text-embedding-ada-002
cohere : embed-english-v3.0, embed-english-light-v3.0,
         embed-multilingual-v3.0, embed-multilingual-light-v3.0
nomic  : nomic-embed-text-v1, nomic-embed-text-v1.5
jina   : jina-embeddings-v3
</code></pre>


<h2>4&nbsp;&nbsp;Bibliometric indicators (AÂ â€¦â€¯I)</h2>

<p>EmbedSLR computes 10â€¯(+1) indicators that quantify topical coherence and internal citation patterns in a publication corpus. All functions are implemented in <code>embedslr/bibliometrics.py</code>.</p>

<table>
<thead><tr><th>Symbol</th><th>Description</th><th>Function</th></tr></thead>
<tbody>
<tr><td>A</td><td>Average number of shared references per pair of papers</td><td><code>indicator_a(df)</code></td></tr>
<tr><td>Aâ€²</td><td>Mean Jaccard (references) across all pairs</td><td><code>indicator_a_prime(df)</code></td></tr>
<tr><td>B</td><td>Average number of shared keywords per pair</td><td><code>indicator_b(df)</code></td></tr>
<tr><td>Bâ€²</td><td>Mean Jaccard (keywords) across all pairs</td><td><code>indicator_b_prime(df)</code></td></tr>
<tr><td>C</td><td>Pairs with â‰¥1 common reference</td><td><code>indicator_c(df)</code></td></tr>
<tr><td>D</td><td>Unique references shared by â‰¥2 papers</td><td><code>indicator_d(df)</code></td></tr>
<tr><td>E</td><td>Total intersections of references across all pairs</td><td><code>indicator_e(df)</code></td></tr>
<tr><td>F</td><td>Pairs with â‰¥1 common keyword</td><td><code>indicator_f(df)</code></td></tr>
<tr><td>G</td><td>Keywords occurring in â‰¥2 papers</td><td><code>indicator_g(df)</code></td></tr>
<tr><td>H</td><td>Average number of mutually cited papers per pair</td><td><code>indicator_h(df)</code></td></tr>
<tr><td>I</td><td>Total unique mutually cited papers</td><td><code>indicator_i(df)</code></td></tr>
</tbody>
</table>

<h3>4.1Â Full report with one call</h3>
<pre><code class="language-python">from embedslr.bibliometrics import full_report
full_report(ranked_df, path="biblio_report.txt", top_n=30)</code></pre>

<h3>4.2Â Single indicator example</h3>
<pre><code class="language-python">from embedslr.bibliometrics import indicator_b_prime
print("Mean Jaccard (keywords):", indicator_b_prime(ranked_df))</code></pre>

<h3>4.3Â Input columns &amp; assumptions</h3>
<ul>
  <li><code>Title</code> and <code>Abstract</code> (autoâ€‘detected; several common Scopus header variants supported).</li>
  <li><code>Author Keywords</code> (optional; created empty if missing).</li>
  <li><code>Parsed_References</code> &mdash; set/list of references. If missing but <code>References</code> exists, the wizard derives it automatically. If neither is present, referenceâ€‘based indicators will be near zero.</li>
</ul>

<h3>4.4Â Outputs &amp; columns</h3>
<ul>
  <li><code>ranking.csv</code> &mdash; sorted by <code>distance_cosine</code> (<em>smaller&nbsp;=&nbsp;closer to query</em>); includes <code>combined_text</code> and, if requested, <code>combined_embeddings</code> (JSON).</li>
  <li><code>biblio_report.txt</code> &mdash; humanâ€‘readable summary of indicatorsÂ Aâ€¦I (optionally limited to Topâ€‘N).</li>
  <li><code>topN.csv</code> &mdash; optional topâ€‘N slice of the ranking.</li>
</ul>


<h2>5&nbsp;&nbsp;Repository structure</h2>

<pre>
embedslr/                 # main package
â”œâ”€â”€ io.py                 # read_csv(), column detection, title+abstract merge
â”œâ”€â”€ embeddings.py         # providers + list_models(), get_embeddings()
â”œâ”€â”€ similarity.py         # cosine ranking (rank_by_cosine)
â”œâ”€â”€ bibliometrics.py      # indicators A â€¦ I + full_report()
â”œâ”€â”€ wizard.py             # interactive terminal assistant (offline pipeline), run()
â”œâ”€â”€ cli.py                # argparse CLI: single 'embedslr' command with flags
â”œâ”€â”€ colab_app.py          # GoogleÂ Colab widget
â”œâ”€â”€ utils.py              # chunk_iterable(), getenv_or_raise(), progress()
â”œâ”€â”€ _version.py           # aux version holder
â””â”€â”€ __init__.py           # public API exports
docs/                     # static docs (this page)
examples/                 # sample data and results
pyproject.toml            # metadata, runtime deps, build backend, entry points
setup.cfg                 # flake8 + packaging extras
MANIFEST.in               # nonâ€‘Python files included in sdist
LICENSE                   # MIT licence
README.md                 # repo front page â€“ quick overview
.gitignore                # build artefacts, __pycache__, *.ipynb_checkpoints
</pre>


<h2>6&nbsp;&nbsp;File highlights</h2>

<ul>
  <li><strong>io.py</strong> â€“ <code>read_csv()</code>, column autoâ€‘detection (<code>autodetect_columns()</code>), <code>combine_title_abstract()</code></li>
  <li><strong>embeddings.py</strong> â€“ functional API for providers (<code>list_models()</code>, <code>get_embeddings()</code>)</li>
  <li><strong>similarity.py</strong> â€“ <code>rank_by_cosine()</code> (ascending by <code>distance_cosine</code>)</li>
  <li><strong>bibliometrics.py</strong> â€“ indicator functions, <code>indicators()</code>, <code>full_report()</code> (<code>top_n</code> is optional; default = full dataset)</li>
  <li><strong>wizard.py</strong> â€“ endâ€‘toâ€‘end pipeline with SBERT offline logic (<code>HF_HUB_OFFLINE=1</code> after first download)</li>
  <li><strong>cli.py</strong> â€“ argparseâ€‘based CLI (no Typer subâ€‘commands)</li>
  <li><strong>colab_app.py</strong> â€“ <code>run()</code> builds the ipywidgets GUI</li>
  <li><strong>utils.py</strong> â€“ <code>chunk_iterable</code>, <code>getenv_or_raise</code>, <code>progress</code></li>
</ul>


<h2>7&nbsp;&nbsp;Citing EmbedSLR</h2>

<pre><code class="language-bibtex">@misc{matysik2025embedslr,
  title  = {EmbedSLRÂ â€“ deterministic embeddingâ€‘based screening and bibliometric validation in SLR},
  author = {Matysik, Sebastian and WiÅ›niewska, Joanna and Frankowski, PaweÅ‚Â K.},
  year   = {2025},
  url    = {https://github.com/s-matysik/EmbedSLR}
}</code></pre>


<h2>8&nbsp;&nbsp;FAQ</h2>

<details>
  <summary><strong>â“Â I have no API key. Can I still use EmbedSLR?</strong></summary>
  <p>Yes. Choose the <kbd>sbert</kbd> provider. The model is downloaded once from HFÂ Hub and then works fully offline.</p>
</details>

<details>
  <summary><strong>â“Â How do I set Topâ€‘N for the metrics?</strong></summary>
  <p>In the wizard, enter the desired number when prompted (<kbd>ğŸ”¢Â Topâ€‘N publications for metrics</kbd>). In the API, pass <code>top_n</code> to <code>full_report()</code>. If you omit <code>top_n</code>, the report is computed on the full dataset.</p>
</details>

<details>
  <summary><strong>â“Â Which environment variables are used for cloud providers?</strong></summary>
  <p><code>OPENAI_API_KEY</code>, <code>COHERE_API_KEY</code>, <code>JINA_API_KEY</code>, <code>NOMIC_API_KEY</code>. You may also pass <code>--api_key</code> in the CLI.</p>
</details>


<p style="margin-top:3rem;font-size:90%;color:#555">This page was generated automatically â€“ last update: <time datetime="2025-08-08">08&nbsp;Aug&nbsp;2025</time>.</p>

</body>
</html>
